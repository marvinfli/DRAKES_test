/n/home03/mfli/.conda/envs/sedd/lib/python3.9/site-packages/norns/cfg.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/n/holylabs/sitanc_lab/Users/mfli/soc-curriculum/DRAKES/drakes_dna/finetune_reward_bp.py:198: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  initialize(config_path="configs_gosai", job_name="load_model")
wandb: Currently logged in as: marvinli (marvinli-harvard-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /n/holylabs/LABS/sitanc_lab/Users/mfli/soc-curriculum/DRAKES/data_and_model/mdlm/reward_bp_results_final/alpha0.001_accum4_bsz32_truncate50_temp1.0_clip1.0_sweep_temp0.5_noise0.5_step50_20250803_001231_20250803_001242/wandb/run-20250803_001243-dtpyevgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run alpha0.001_accum4_bsz32_truncate50_temp1.0_clip1.0_sweep_temp0.5_noise0.5_step50_20250803_001231_20250803_001242
wandb: ⭐️ View project at https://wandb.ai/marvinli-harvard-university/reward_bp_final
wandb: 🚀 View run at https://wandb.ai/marvinli-harvard-university/reward_bp_final/runs/dtpyevgr
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: Downloading large artifact human_state_dict:latest, 939.29MB. 1 files... 
wandb:   1 of 1 files downloaded.  
Done. 0:0:5.0 (186.6MB/s)
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: Downloading large artifact human_state_dict:latest, 939.29MB. 1 files... 
wandb:   1 of 1 files downloaded.  
Done. 0:0:0.6 (1696.2MB/s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████
wandb:     inverse_temp ▁▁▁▁▁▂▃▄▄▄▄▅▅▅▆▆▆▆▇▇████████████████████
wandb:     mean kl loss ▁▂▆▆▅▅▅▆▆▆▇▇▆▆▇▇█▇▆▇█▇▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▆
wandb: mean reward loss █▇▇▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁
wandb:   mean_grad_norm ▂▁▂▅▂▅▃▁▂▂▃▁▃▄▃▂▂▄▄▂▃▄█▃▆▆▃▇▅▆▆▃▅▃▅▂▄▂▄▃
wandb:        mean_loss ███▇█▂▂▂▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁▂▂▁▁
wandb:      mean_reward ▁▁▁▂█▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇████▇▇▇▇▇███▇██████
wandb: mean_reward_eval ▁▁███▇▇▇▇▆▆▆▇▇▆▆▆▇▇▇▇▆▆▇█▇▇▇▇▇▆▇▆▇▆▇▇▆▇▆
wandb:   multiply_noise ▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:            epoch 999
wandb:     inverse_temp 1
wandb:     mean kl loss 495.51413
wandb: mean reward loss -5.97191
wandb:   mean_grad_norm 16.53183
wandb:        mean_loss -5.4764
wandb:      mean_reward 5.97191
wandb: mean_reward_eval 4.9247
wandb:   multiply_noise 0
wandb: 
wandb: 🚀 View run alpha0.001_accum4_bsz32_truncate50_temp1.0_clip1.0_sweep_temp0.5_noise0.5_step50_20250803_001231_20250803_001242 at: https://wandb.ai/marvinli-harvard-university/reward_bp_final/runs/dtpyevgr
wandb: ⭐️ View project at: https://wandb.ai/marvinli-harvard-university/reward_bp_final
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /n/holylabs/LABS/sitanc_lab/Users/mfli/soc-curriculum/DRAKES/data_and_model/mdlm/reward_bp_results_final/alpha0.001_accum4_bsz32_truncate50_temp1.0_clip1.0_sweep_temp0.5_noise0.5_step50_20250803_001231_20250803_001242/wandb/run-20250803_001243-dtpyevgr/logs
